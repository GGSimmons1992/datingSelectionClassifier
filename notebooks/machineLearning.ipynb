{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "283e38b5-dbdb-48a3-901b-2d4c6fe803f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(5000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 5 seconds\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from os.path import exists\n",
    "from os import remove\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.model_selection as ms\n",
    "from sklearn.model_selection import cross_validate\n",
    "import sklearn.linear_model as lm\n",
    "from sklearn.neighbors import KNeighborsClassifier as knn\n",
    "from sklearn.ensemble import GradientBoostingClassifier as grad\n",
    "from sklearn.ensemble import RandomForestRegressor as rf\n",
    "from sklearn import metrics\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, \"../util/\")\n",
    "import util as util\n",
    "\n",
    "%autosave 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f53352-c019-4b18-ad90-c9ec7e010d29",
   "metadata": {},
   "source": [
    "# Adding dummies and train-test-split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f609dd8-54ac-4fdf-929d-1c6870d95fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "datingTrainExists = exists('../data/processedData/datingTrain.csv')\n",
    "datingTestExists = exists('../data/processedData/datingTest.csv')\n",
    "datingFullExists = exists('../data/processedData/datingFull.csv')\n",
    "\n",
    "relatedDummiesDictionaryExists = exists('../data/processedData/relatedDummiesDictionary.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6bdd5e57-935f-47f6-baa4-506a1ec62765",
   "metadata": {},
   "outputs": [],
   "source": [
    "if exists('../data/processedData/columnDataDictionary.json'):\n",
    "    with open('../data/processedData/columnDataDictionary.json') as d:\n",
    "        columnDataDictionary = json.load(d)\n",
    "else:\n",
    "    with open('../data/columnDataDictionary.json') as d:\n",
    "        columnDataDictionary = json.load(d)\n",
    "columnList = columnDataDictionary['columnList']\n",
    "nonBinaryCategoricalList = columnDataDictionary['nonBinaryCategoricalList']\n",
    "stringToFloatList = columnDataDictionary['stringToFloatList']\n",
    "pointDistributionList = columnDataDictionary['pointDistributionList']\n",
    "partnerList = columnDataDictionary['partnerList']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c38d144-9101-4d6a-802b-192a9d08ac73",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-32e0a05b2abf>:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  blindDateData[col] = blindDateData[col].str.replace(',', '').astype(float)\n",
      "<ipython-input-4-32e0a05b2abf>:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  blindDateData['zipcode'] = blindDateData['zipcode'].apply(str)\n",
      "<ipython-input-4-32e0a05b2abf>:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  blindDateData['zipcode'] = blindDateData['zipcode'].str.replace(',', '')\n",
      "<ipython-input-4-32e0a05b2abf>:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  blindDateData[col] = blindDateData[col].apply(str)\n",
      "<ipython-input-4-32e0a05b2abf>:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  blindDateData[col]=blindDateData[col].fillna('nan')\n",
      "<ipython-input-4-32e0a05b2abf>:64: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  datingTrain['match'] = matchTrain\n",
      "<ipython-input-4-32e0a05b2abf>:65: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  datingTest['match'] = matchTest\n"
     ]
    }
   ],
   "source": [
    "if (datingTrainExists and datingTestExists and datingFullExists and relatedDummiesDictionaryExists):\n",
    "    datingTrain = pd.read_csv('../data/processedData/datingTrain.csv')\n",
    "    datingTest = pd.read_csv('../data/processedData/datingTest.csv')\n",
    "    datingFull = pd.read_csv('../data/processedData/datingFull.csv')\n",
    "    \n",
    "    with open('../data/processedData/relatedDummiesDictionary.json') as d:\n",
    "        relatedDummiesDictionary = json.load(d)\n",
    "    for df in [datingTrain,datingTest,datingFull]:\n",
    "        df['zipcode'] = df['zipcode'].apply(str)\n",
    "        if 'zipcode_o' in list(df.columns):\n",
    "            df['zipcode_o'] = df['zipcode_o'].apply(str)\n",
    "        for col in nonBinaryCategoricalList:\n",
    "            if col in list(df.columns):\n",
    "                df[col] = df[col].apply(str)\n",
    "        \n",
    "else:\n",
    "    !rm -r ../data/processedData\n",
    "    !mkdir ../data/processedData\n",
    "    \n",
    "    datingData = pd.read_csv('../data/encoded-SpeedDatingData-WithLocations.csv')   \n",
    "    \n",
    "    blindDateData = datingData[columnList]\n",
    "    \n",
    "    for col in stringToFloatList:\n",
    "        blindDateData[col] = blindDateData[col].str.replace(',', '').astype(float)\n",
    "    \n",
    "    blindDateData['zipcode'] = blindDateData['zipcode'].apply(str)\n",
    "    blindDateData['zipcode'] = blindDateData['zipcode'].str.replace(',', '')\n",
    "    \n",
    "    for col in nonBinaryCategoricalList:\n",
    "        blindDateData[col] = blindDateData[col].apply(str)\n",
    "    \n",
    "    blindDateCategoricalData = blindDateData.select_dtypes(include=['O'])\n",
    "    for col in blindDateCategoricalData.columns:\n",
    "        blindDateData[col]=blindDateData[col].fillna('nan')\n",
    "    relatedDummiesDictionary = {}\n",
    "    for col in blindDateCategoricalData.columns:\n",
    "        dummyData = pd.get_dummies(blindDateData[col],prefix=col,drop_first=True)\n",
    "        if len(dummyData.columns) <= 21:\n",
    "            for dummyCol in dummyData.columns:\n",
    "                relatedDummiesDictionary[str(dummyCol)] = list(dummyData.columns)\n",
    "                if col in partnerList:\n",
    "                    partnerList.append(str(dummyCol))\n",
    "            blindDateData = pd.concat([blindDateData,dummyData],axis=1)\n",
    "    with open('../data/processedData/relatedDummiesDictionary.json', 'w') as fp:\n",
    "        json.dump(relatedDummiesDictionary, fp)\n",
    "        \n",
    "    partnerList = list(set(partnerList))\n",
    "    columnDataDictionary = {\"columnList\": columnList,\n",
    "                        \"nonBinaryCategoricalList\": nonBinaryCategoricalList,\n",
    "                        \"stringToFloatList\": stringToFloatList,\n",
    "                        \"pointDistributionList\": pointDistributionList,\n",
    "                        \"partnerList\": partnerList}\n",
    "\n",
    "    with open('../data/processedData/columnDataDictionary.json', 'w') as fp:\n",
    "            json.dump(columnDataDictionary, fp)\n",
    "    \n",
    "    datingFull = blindDateData.copy()\n",
    "    match = datingFull['match']\n",
    "    X = datingFull.drop(['match'], axis=1)\n",
    "    \n",
    "    datingTrain, datingTest, matchTrain, matchTest = train_test_split(X, match, test_size=0.2)\n",
    "    \n",
    "    datingTrain['match'] = matchTrain\n",
    "    datingTest['match'] = matchTest\n",
    "    \n",
    "    datingTrain.to_csv('../data/processedData/datingTrain.csv',index=False)\n",
    "    datingTest.to_csv('../data/processedData/datingTest.csv',index=False)\n",
    "    datingFull.to_csv('../data/processedData/datingFull.csv',index=False)\n",
    "    \n",
    "    dummyColumns = list(relatedDummiesDictionary.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c695ed-1396-49fb-ae29-736e77d59d69",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ebd90ed-cccb-437b-a07e-1b153772db7c",
   "metadata": {},
   "source": [
    "### Join partner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3addb68-04fb-4afe-a7c8-dbd8d6825eb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../util/util.py:61: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  partner_o['iid_o'] = partner_o['iid']\n",
      "../util/util.py:62: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  partner_o['pid_o'] = partner_o['pid']\n"
     ]
    }
   ],
   "source": [
    "for partnerCol in partnerList:\n",
    "    if ((\"_o\" not in str(partnerCol)) and (partnerCol+\"_o\" not in datingTrain.columns)):\n",
    "        partner = datingFull.copy()\n",
    "        datingTrain = util.joinToPartner(datingTrain,partner)\n",
    "        datingTrain.to_csv('../data/processedData/datingTrain.csv',index=False)\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de70f81-b475-42fe-9dc7-8c107f2d28f8",
   "metadata": {},
   "source": [
    "### Get distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc4da6bb-d52b-4a7f-8ece-fe8de5dcea23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "06:30:39\n",
      "0 of 6702: 0.0% complete\n",
      "0.0% of data is None\n"
     ]
    }
   ],
   "source": [
    "if \"partnerDistance\" not in datingTrain.columns:\n",
    "    datingTrain = util.returnDFWithpartnerDistance(datingTrain,\"train\",True)\n",
    "    datingTrain.to_csv('../data/processedData/datingTrain.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b97881f-1b42-4fd3-bcd8-b1c5ddc56cde",
   "metadata": {},
   "source": [
    "### Fix met value according to [The Data Science Book of Love](https://www.kaggle.com/code/lucabasa/the-data-science-book-of-love/notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ff33c9e-b9a9-4939-a298-a0ad84036181",
   "metadata": {},
   "outputs": [],
   "source": [
    "if max(datingTrain['met']) > 1 or max(datingTrain['met_o']) > 1:\n",
    "    datingTrain.loc[datingTrain.met.isna(), 'met'] = 0\n",
    "    datingTrain.loc[datingTrain.met_o.isna(), 'met_o'] = 0\n",
    "\n",
    "    datingTrain.loc[datingTrain.met < 2, 'met'] = 0\n",
    "    datingTrain.loc[datingTrain.met_o < 2, 'met_o'] = 0\n",
    "    datingTrain.loc[datingTrain.met > 1, 'met'] = 1\n",
    "    datingTrain.loc[datingTrain.met_o > 1, 'met_o'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d629b9d5-3238-4fe4-bdc7-421fb93ea28d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Fix ambiguous scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ede98e0-c807-43b3-976b-4728aece576b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/garysimmons/opt/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3437, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-8-f2fc5cf8990a>\", line 4, in <module>\n",
      "    datingTrain = util.fixAmbiguousScores(datingTrain)\n",
      "  File \"../util/util.py\", line 226, in fixAmbiguousScores\n",
      "    df = redistributePoints(df)\n",
      "  File \"../util/util.py\", line 243, in redistributePoints\n",
      "    row = df.iloc[rowindex]\n",
      "  File \"/Users/garysimmons/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\", line 895, in __getitem__\n",
      "    return self._getitem_axis(maybe_callable, axis=axis)\n",
      "  File \"/Users/garysimmons/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\", line 1503, in _getitem_axis\n",
      "    return self.obj._ixs(key, axis=axis)\n",
      "  File \"/Users/garysimmons/opt/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\", line 2947, in _ixs\n",
      "    new_values = self._mgr.fast_xs(i)\n",
      "  File \"/Users/garysimmons/opt/anaconda3/lib/python3.8/site-packages/pandas/core/internals/managers.py\", line 968, in fast_xs\n",
      "    result[rl] = blk.iget((i, loc))\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/garysimmons/opt/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2061, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/garysimmons/opt/anaconda3/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/Users/garysimmons/opt/anaconda3/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/Users/garysimmons/opt/anaconda3/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/Users/garysimmons/opt/anaconda3/lib/python3.8/inspect.py\", line 1515, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/Users/garysimmons/opt/anaconda3/lib/python3.8/inspect.py\", line 1473, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/Users/garysimmons/opt/anaconda3/lib/python3.8/inspect.py\", line 708, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/Users/garysimmons/opt/anaconda3/lib/python3.8/inspect.py\", line 754, in getmodule\n",
      "    os.path.realpath(f)] = module.__name__\n",
      "  File \"/Users/garysimmons/opt/anaconda3/lib/python3.8/posixpath.py\", line 391, in realpath\n",
      "    path, ok = _joinrealpath(filename[:0], filename, {})\n",
      "  File \"/Users/garysimmons/opt/anaconda3/lib/python3.8/posixpath.py\", line 425, in _joinrealpath\n",
      "    if not islink(newpath):\n",
      "  File \"/Users/garysimmons/opt/anaconda3/lib/python3.8/posixpath.py\", line 167, in islink\n",
      "    st = os.lstat(path)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-f2fc5cf8990a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhalfwayChangeColumns\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mdatingTrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfixAmbiguousScores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatingTrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhalfwayQuestionSanityTest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatingTrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/NYCDSA/projects/datingSelectionClassifier/util/util.py\u001b[0m in \u001b[0;36mfixAmbiguousScores\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m    225\u001b[0m     \u001b[0mhalfwayQuestionSanityTest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 226\u001b[0;31m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mredistributePoints\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    227\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapplyHalfwayChange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/NYCDSA/projects/datingSelectionClassifier/util/util.py\u001b[0m in \u001b[0;36mredistributePoints\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m    242\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mrowindex\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 243\u001b[0;31m                 \u001b[0mrow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrowindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    244\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misNan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mquestionSumString\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mquestionSumString\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    894\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1502\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1503\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ixs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1504\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_ixs\u001b[0;34m(self, i, axis)\u001b[0m\n\u001b[1;32m   2946\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2947\u001b[0;31m             \u001b[0mnew_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfast_xs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2948\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mfast_xs\u001b[0;34m(self, loc)\u001b[0m\n\u001b[1;32m    967\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrl\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmgr_locs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 968\u001b[0;31m                 \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrl\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    969\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2060\u001b[0m                         \u001b[0;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2061\u001b[0;31m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2062\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'KeyboardInterrupt' object has no attribute '_render_traceback_'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2061\u001b[0m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2062\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2063\u001b[0;31m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0m\u001b[1;32m   2064\u001b[0m                                             value, tb, tb_offset=tb_offset)\n\u001b[1;32m   2065\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1365\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1366\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1367\u001b[0;31m         return FormattedTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1368\u001b[0m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[1;32m   1369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1265\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose_modes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1266\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1267\u001b[0;31m             return VerboseTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1268\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1269\u001b[0m             )\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1122\u001b[0m         \u001b[0;34m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1124\u001b[0;31m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0m\u001b[1;32m   1125\u001b[0m                                                                tb_offset)\n\u001b[1;32m   1126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1080\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1082\u001b[0;31m         \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[0;34m(etype, value, records)\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m     \u001b[0;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "halfwayChangeColumns = [str(col) for col in datingTrain.columns if ((\"1_s\" in str(col)) | (\"3_s\" in str(col)))]\n",
    "\n",
    "if(len(halfwayChangeColumns) > 0):\n",
    "    datingTrain = util.fixAmbiguousScores(datingTrain)\n",
    "    util.halfwayQuestionSanityTest(datingTrain)\n",
    "    datingTrain.to_csv('../data/processedData/datingTrain.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4444c2d-2bae-4e16-848d-5035c7700c62",
   "metadata": {},
   "source": [
    "### Replace Nans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a1fe4d-f74a-4a20-a5e5-9924a44d97bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "datingTrainNumerical = datingTrain.select_dtypes(include=['uint8','int64','float64']).drop('match',axis = 1)\n",
    "\n",
    "if (exists('../data/processedData/trainNanReplacementValuesDictionary.json')):\n",
    "    with open('../data/processedData/trainNanReplacementValuesDictionary.json') as d:\n",
    "        trainNanReplacementValuesDictionary = json.load(d)\n",
    "else:\n",
    "    trainNanReplacementValuesDictionary = {}\n",
    "    for col in datingTrainNumerical:\n",
    "        if col in [\"age\",\"age_o\",\"pf_o_att\",\"pf_o_sin\",\"pf_o_int\",\"pf_o_fun\",\"pf_o_amb\",\"pf_o_sha\",\"attr_o\",\"sinc_o\",\"intel_o\",\"mn_sat\",\"tuition\",\"income\",\n",
    "                   \"sports\",\"tvsports\",\"exercise\",\"dining\",\"museums\",\"art\",\"hiking\",\"gaming\",\"reading\",\"tv\",\n",
    "                  \"theater\",\"movies\",\"concerts\",\"music\",\"shopping\",\"yoga\",\"exphappy\",\"expnum\",\"attr1_1\",\"sinc1_1\",\"intel1_1\",\"fun1_1\",\"shar1_1\",\"attr4_1\",\"sinc4_1\",\n",
    "                  \"intel4_1\",\"fun4_1\",\"shar4_1\",\"attr2_1\",\"sinc2_1\",\"intel2_1\",\"fun2_1\",\"shar2_1\",\"attr3_1\",\"sinc3_1\",\"intel3_1\",\"fun3_1\",\"attr5_1\",\"sinc5_1\",\n",
    "                   \"intel5_1\",\"fun5_1\",\"match_es\",\"sports_o\",\"tvsports_o\",\"exercise_o\",\"dining_o\",\"museums_o\",\"art_o\",\n",
    "                  \"hiking_o\",\"gaming_o\",\"clubbing_o\",\"reading_o\",\"tv_o\",\"theater_o\",\"movies_o\",\"concerts_o\",\"music_o\",\"shopping_o\",\"yoga_o\",\"exphappy_o\",\"expnum_o\",\n",
    "                   \"attr4_1_o\",\"sinc4_1_o\",\"intel4_1_o\",\"fun4_1_o\",\"shar4_1_o\",\"attr2_1_o\",\"sinc2_1_o\",\"intel2_1_o\",\"fun2_1_o\",\"shar2_1_o\",\"attr3_1_o\",\"sinc3_1_o\",\n",
    "                   \"intel3_1_o\",\"fun3_1_o\",\"attr5_1_o\",\"sinc5_1_o\",\"intel5_1_o\",\"fun5_1_o\",\"match_es_o\",\"lats\",\"lons\",\"lats_o\",\"lons_o\",\"partnerDistance\"]:\n",
    "            trainNanReplacementValuesDictionary[str(col)] = datingTrainNumerical[col].mean()\n",
    "        elif col in [\"imprace\",\"imprelig\",\"zipcode\",\"goal\",\"date\",\"go_out\",\"career_c\",\"met\",\"imprace_o\",\"imprelig_o\",\"zipcode_o\",\"goal_o\",\"date_o\",\"career_c_o\"]:\n",
    "            trainNanReplacementValuesDictionary[str(col)] = round(np.mean(datingTrainNumerical[col].mode().values))\n",
    "        else:\n",
    "            trainNanReplacementValuesDictionary[str(col)] = 0\n",
    "    with open('../data/processedData/trainNanReplacementValuesDictionary.json', 'w') as fp:\n",
    "        json.dump(trainNanReplacementValuesDictionary, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d48406-ee7c-4e34-b985-f0b2a325363d",
   "metadata": {},
   "outputs": [],
   "source": [
    "datingTrain = util.replaceNansWithTrainingDataValues(datingTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8d5404-6b95-45db-904c-34fb731b1f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = datingTrainNumerical\n",
    "match = datingTrain[\"match\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "911fcbe2-48f5-470d-8dbf-d59feb48cec9",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248dff16-8447-41c3-9aa4-01d8f87f90e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sqrtn = np.floor(np.sqrt(X.shape[0]))\n",
    "sqrtfeatures = np.floor(np.sqrt(X.shape[1]))\n",
    "log2features = np.floor(np.log2(X.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fccf544a-51dc-4d1d-9619-654cc93ac168",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b9ea2c-f42e-43fc-aa66-1f5a9495d8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "logModel = lm.LogisticRegression()\n",
    "logModel.fit(X,match)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5508ffa-dea4-49d3-8d1c-333f80a4f625",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6189043-4923-4cbb-81fd-716a99682330",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn5 = knn(n_neighbors=5)\n",
    "knnsqrtn = knn(n_neighbors=sqrtn)\n",
    "knn5.fit(X,match)\n",
    "knnsqrtn.fit(X,match)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "767c1e00-aac9-487b-92b6-b0766b1ab8b9",
   "metadata": {},
   "source": [
    "## Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa52d8bd-bca9-4366-91c9-6ae12753e58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "gradientdeci = grad(learning_rate=0.1)\n",
    "gradientdeka = grad(learning_rate=10)\n",
    "gradientdeci.fit(X,match)\n",
    "gradientdeka.fit(X,match)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6304b01-3857-4bd0-ae45-1d9831a1d334",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ec3947-934b-42ae-a30b-99d4b32d7fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if exists(\"../data/processedData/forestParams.json\"):\n",
    "    with open('../data/processedData/forestParams.json') as d:\n",
    "        forestParams = json.load(d)\n",
    "        accurateForestParams = forestParams[\"accurateForestParams\"]\n",
    "        recallForestParams = forestParams[\"recallForestParams\"]\n",
    "else:\n",
    "    n_estimator_list = list(np.linspace(100,1000,11))\n",
    "    searchParams = [{\n",
    "        \"criterion\":[\"gini\",\"entropy\",\"log_loss\"],\n",
    "        \"n_estimators\": n_estimator_list,\n",
    "        \"max_depth\":[sqrtfeatures,log2features,None],\n",
    "        \"max_features\":[\"sqrt\",\"log2\",None]\n",
    "    }]\n",
    "\n",
    "    accurateForest0 = rf()\n",
    "    recallForest0 = rf()\n",
    "\n",
    "    accurateForestGrid = ms.GridSearchCV(accurateForest0, searchParams, scoring='accuracy')\n",
    "    recallForestGrid = ms.GridSearchCV(recallForest0, searchParams, scoring='recall')\n",
    "\n",
    "    accurateForestGrid.fit(X,match)\n",
    "    recallForestGrid.fit(X,match)\n",
    "\n",
    "    accurateForestParams = accurateForestGrid.best_params_\n",
    "    recallForestParams = recallForestGrid.best_params_\n",
    "    forestParams = {\n",
    "        \"accurateForestParams\": accurateForestParams,\n",
    "        \"recallForestParams\": recallForestParams\n",
    "    }\n",
    "    with open(\"../data/processedData/forestParams.json\", 'w') as fp:\n",
    "        json.dump(forestParams, fp)\n",
    "    \n",
    "accurateForest = rf(n_estimators = accurateForestParams[\"n_estimators\"],\n",
    "                    criterion = accurateForestParams[\"criterion\"],\n",
    "                    max_depth = accurateForestParams[\"max_depth\"],\n",
    "                    max_depth = accurateForestParams[\"max_depth\"])\n",
    "recallForest = rf(n_estimators = recallForestParams[\"n_estimators\"],\n",
    "                    criterion = recallForestParams[\"criterion\"],\n",
    "                    max_depth = recallForestParams[\"max_depth\"],\n",
    "                    max_depth = recallForestParams[\"max_depth\"])\n",
    "\n",
    "accurateForest.fit(X,match)\n",
    "recallForest.fit(X,match)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e0d71d-dbd6-4075-8f9e-fc57118d0ee4",
   "metadata": {},
   "source": [
    "# Individual Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e41fa1-50ce-4fd6-85b3-c9ec47b37a53",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe7aec2-8e5e-4b55-8feb-c22af75e031d",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2830fb95-9857-4d16-b538-62c025b07b47",
   "metadata": {},
   "source": [
    "## Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d72fb6-44f4-4e30-8e43-02c8133a28c0",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87fa7875-d2a8-4e24-aa49-25d005b1e8a5",
   "metadata": {},
   "source": [
    "# Ensemble Testing"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
