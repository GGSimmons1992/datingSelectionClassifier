{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "283e38b5-dbdb-48a3-901b-2d4c6fe803f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(5000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 5 seconds\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from os.path import exists\n",
    "from os import remove\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.model_selection as ms\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import metrics\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, \"../util/\")\n",
    "import util as util\n",
    "\n",
    "%autosave 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f53352-c019-4b18-ad90-c9ec7e010d29",
   "metadata": {},
   "source": [
    "# Adding dummies and train-test-split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f609dd8-54ac-4fdf-929d-1c6870d95fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "datingTrainWithDummiesExists = exists('../data/datingTrainWithDummies.csv')\n",
    "datingTestWithDummiesExists = exists('../data/datingTestWithDummies.csv')\n",
    "datingTrainWithoutDummiesExists = exists('../data/datingTrainWithoutDummies.csv')\n",
    "datingTestWithoutDummiesExists = exists('../data/datingTestWithoutDummies.csv')\n",
    "datingFullWithDummiesExists = exists('../data/datingFullWithDummies.csv')\n",
    "datingFullWithoutDummiesExists = exists('../data/datingFullWithoutDummies.csv')\n",
    "\n",
    "relatedDummiesDictionaryExists = exists('../data/relatedDummiesDictionary.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6bdd5e57-935f-47f6-baa4-506a1ec62765",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/columnDataDictionary.json') as d:\n",
    "    columnDataDictionary = json.load(d)\n",
    "columnList = columnDataDictionary['columnList']\n",
    "nonBinaryCategoricalList = columnDataDictionary['nonBinaryCategoricalList']\n",
    "stringToFloatList = columnDataDictionary['stringToFloatList']\n",
    "pointDistributionList = columnDataDictionary['pointDistributionList']\n",
    "partnerList = columnDataDictionary['partnerList']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c38d144-9101-4d6a-802b-192a9d08ac73",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/garysimmons/opt/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3165: DtypeWarning: Columns (27) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "if (datingTrainWithDummiesExists and datingTestWithDummiesExists and datingFullWithDummiesExists and\n",
    "    datingTrainWithoutDummiesExists and datingTestWithoutDummiesExists and datingFullWithoutDummiesExists and\n",
    "    relatedDummiesDictionaryExists):\n",
    "    datingTrainWithDummies = pd.read_csv('../data/datingTrainWithDummies.csv')\n",
    "    datingTestWithDummies = pd.read_csv('../data/datingTestWithDummies.csv')\n",
    "    datingTrainWithoutDummies = pd.read_csv('../data/datingTrainWithoutDummies.csv')\n",
    "    datingTestWithoutDummies = pd.read_csv('../data/datingTestWithoutDummies.csv')\n",
    "    datingFullWithDummies = pd.read_csv('../data/datingFullWithDummies.csv')\n",
    "    datingFullWithoutDummies = pd.read_csv('../data/datingFullWithoutDummies.csv')\n",
    "    \n",
    "    with open('../data/relatedDummiesDictionary.json') as d:\n",
    "        relatedDummiesDictionary = json.load(d)\n",
    "    for df in [datingTrainWithDummies,datingTestWithDummies,datingFullWithDummies,datingTrainWithoutDummies,datingTestWithoutDummies,datingFullWithoutDummies]:\n",
    "        df['zipcode'] = df['zipcode'].apply(str)\n",
    "        if 'zipcode_o' in list(df.columns):\n",
    "            df['zipcode_o'] = df['zipcode_o'].apply(str)\n",
    "        for col in nonBinaryCategoricalList:\n",
    "            if col in list(df.columns):\n",
    "                df[col] = df[col].apply(str)\n",
    "        \n",
    "else:\n",
    "    if (datingTrainWithDummiesExists):\n",
    "        remove('../data/datingTrainWithDummies.csv')\n",
    "    if (datingTestWithDummiesExists):\n",
    "        remove('../data/datingTestWithDummies.csv')\n",
    "    if (datingTrainWithoutDummiesExists):\n",
    "        remove('../data/datingTrainWithoutDummies.csv')\n",
    "    if (datingTestWithoutDummiesExists):\n",
    "        remove('../data/datingTestWithoutDummies.csv')\n",
    "    if (datingFullWithDummiesExists):\n",
    "        remove('../data/datingFullWithDummies.csv')\n",
    "    if (datingFullWithoutDummiesExists):\n",
    "        remove('../data/datingFullWithoutDummies.csv')\n",
    "    if (relatedDummiesDictionaryExists):\n",
    "        remove('../data/relatedDummiesDictionary.json')\n",
    "    \n",
    "    !jupyter nbconvert --execute eda.ipynb\n",
    "    \n",
    "    datingData = pd.read_csv('../data/encoded-SpeedDatingData.csv')\n",
    "    blindDateData = datingData[columnList]\n",
    "    \n",
    "    for col in stringToFloatList:\n",
    "        blindDateData[col] = blindDateData[col].str.replace(',', '').astype(float)\n",
    "    blindDateData['zipcode'] = blindDateData['zipcode'].str.replace(',', '')\n",
    "    for col in nonBinaryCategoricalList:\n",
    "        blindDateData[col] = blindDateData[col].apply(str)\n",
    "    \n",
    "    blindDateCategoricalData = blindDateData.select_dtypes(include=['O'])\n",
    "    for col in blindDateCategoricalData.columns:\n",
    "        blindDateData[col]=blindDateData[col].fillna('nan')\n",
    "    relatedDummiesDictionary = {}\n",
    "    for col in blindDateCategoricalData.columns:\n",
    "        dummyData = pd.get_dummies(blindDateData[col],prefix=col,drop_first=True)\n",
    "        for dummyCol in dummyData.columns:\n",
    "            relatedDummiesDictionary[str(dummyCol)] = list(dummyData.columns)\n",
    "            if col in partnerList:\n",
    "                partnerList.append(str(dummyCol))\n",
    "        blindDateData = pd.concat([blindDateData,dummyData],axis=1)\n",
    "    with open('../data/relatedDummiesDictionary.json', 'w') as fp:\n",
    "        json.dump(relatedDummiesDictionary, fp)\n",
    "        \n",
    "    partnerList = list(set(partnerList))\n",
    "    columnDataDictionary = {\"columnList\": columnList,\n",
    "                        \"nonBinaryCategoricalList\": nonBinaryCategoricalList,\n",
    "                        \"stringToFloatList\": stringToFloatList,\n",
    "                        \"pointDistributionList\": pointDistributionList,\n",
    "                        \"partnerList\": partnerList}\n",
    "\n",
    "    with open('../data/columnDataDictionary.json', 'w') as fp:\n",
    "            json.dump(columnDataDictionary, fp)\n",
    "    \n",
    "    datingFullWithDummies = blindDateData.copy()\n",
    "    match = datingFullWithDummies['match']\n",
    "    X = datingFullWithDummies.drop(['match'], axis=1)\n",
    "    \n",
    "    datingTrainWithDummies, datingTestWithDummies, matchTrain, matchTest = train_test_split(X, match, test_size=0.2)\n",
    "    \n",
    "    datingTrainWithDummies['match'] = matchTrain\n",
    "    datingTestWithDummies['match'] = matchTest\n",
    "    \n",
    "    datingTrainWithDummies.to_csv('../data/datingTrainWithDummies.csv',index=False)\n",
    "    datingTestWithDummies.to_csv('../data/datingTestWithDummies.csv',index=False)\n",
    "    datingFullWithDummies.to_csv('../data/datingFullWithDummies.csv',index=False)\n",
    "    \n",
    "    dummyColumns = list(relatedDummiesDictionary.keys())\n",
    "    datingTrainWithoutDummies = datingTrainWithDummies.drop(dummyColumns, axis=1)\n",
    "    datingTestWithoutDummies = datingTestWithDummies.drop(dummyColumns, axis=1)\n",
    "    datingFullWithoutDummies = datingFullWithDummies.drop(dummyColumns, axis=1)\n",
    "    \n",
    "    datingTrainWithoutDummies.to_csv('../data/datingTrainWithoutDummies.csv',index=False)\n",
    "    datingTestWithoutDummies.to_csv('../data/datingTestWithoutDummies.csv',index=False)\n",
    "    datingFullWithoutDummies.to_csv('../data/datingFullWithoutDummies.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c695ed-1396-49fb-ae29-736e77d59d69",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ebd90ed-cccb-437b-a07e-1b153772db7c",
   "metadata": {},
   "source": [
    "### Join partner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3addb68-04fb-4afe-a7c8-dbd8d6825eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for partnerCol in partnerList:\n",
    "    if ((\"_o\" not in str(partnerCol)) and (partnerCol+\"_o\" not in datingTrainWithoutDummies.columns) and (partnerCol+\"_o\" not in datingTrainWithDummies.columns)):\n",
    "        partnerWithDummies = datingFullWithDummies.copy()\n",
    "        partnerWithoutDummies = datingFullWithoutDummies.copy()\n",
    "        datingTrainWithDummies = util.joinToPartner(datingTrainWithDummies,partnerWithDummies)\n",
    "        datingTrainWithoutDummies = util.joinToPartner(datingTrainWithoutDummies,partnerWithoutDummies)\n",
    "        datingTrainWithDummies.to_csv('../data/datingTrainWithDummies.csv',index=False)\n",
    "        datingTrainWithoutDummies.to_csv('../data/datingTrainWithoutDummies.csv',index=False)\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de70f81-b475-42fe-9dc7-8c107f2d28f8",
   "metadata": {},
   "source": [
    "### Get distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc4da6bb-d52b-4a7f-8ece-fe8de5dcea23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "09:27:40\n",
      "0 of 6702: 0.0% complete\n",
      "0.0% of data is None\n",
      "09:32:41\n",
      "100 of 6702: 1.4920919128618322% complete\n",
      "0.3133393017009848% of data is None\n",
      "09:37:41\n",
      "200 of 6702: 2.9841838257236644% complete\n",
      "0.5819158460161146% of data is None\n",
      "09:42:39\n",
      "299 of 6702: 4.461354819456878% complete\n",
      "0.925096985974336% of data is None\n",
      "09:47:41\n",
      "399 of 6702: 5.953446732318711% complete\n",
      "1.1936735302894659% of data is None\n",
      "09:52:40\n",
      "498 of 6702: 7.430617726051925% complete\n",
      "1.4920919128618322% of data is None\n",
      "09:57:38\n",
      "597 of 6702: 8.907788719785138% complete\n",
      "1.805431214562817% of data is None\n",
      "10:02:40\n",
      "697 of 6702: 10.39988063264697% complete\n",
      "2.0590868397493285% of data is None\n",
      "10:07:39\n",
      "796 of 6702: 11.877051626380185% complete\n",
      "2.5663980901223513% of data is None\n",
      "10:12:41\n",
      "896 of 6702: 13.369143539242017% complete\n",
      "2.909579230080573% of data is None\n",
      "10:17:40\n",
      "995 of 6702: 14.846314532975232% complete\n",
      "3.327364965681886% of data is None\n",
      "10:22:41\n",
      "1095 of 6702: 16.338406445837062% complete\n",
      "3.640704267382871% of data is None\n",
      "10:27:40\n",
      "1194 of 6702: 17.815577439570276% complete\n",
      "3.924201730826619% of data is None\n",
      "10:32:39\n",
      "1293 of 6702: 19.29274843330349% complete\n",
      "4.222620113398985% of data is None\n",
      "10:37:41\n",
      "1393 of 6702: 20.784840346165325% complete\n",
      "4.6553267681289165% of data is None\n",
      "10:42:39\n",
      "1492 of 6702: 22.26201133989854% complete\n",
      "4.998507908087138% of data is None\n",
      "10:47:40\n",
      "1592 of 6702: 23.75410325276037% complete\n",
      "5.326768128916742% of data is None\n",
      "10:52:39\n",
      "1691 of 6702: 25.231274246493584% complete\n",
      "5.61026559236049% of data is None\n",
      "10:57:40\n",
      "1791 of 6702: 26.723366159355415% complete\n",
      "5.923604894061474% of data is None\n",
      "11:02:41\n",
      "1891 of 6702: 28.21545807221725% complete\n",
      "6.132497761862131% of data is None\n",
      "11:07:40\n",
      "1990 of 6702: 29.692629065950463% complete\n",
      "6.505520740077589% of data is None\n",
      "11:12:39\n",
      "2089 of 6702: 31.169800059683677% complete\n",
      "6.863622799164428% of data is None\n",
      "11:17:41\n",
      "2189 of 6702: 32.66189197254551% complete\n",
      "7.251566696508505% of data is None\n",
      "11:22:39\n",
      "2288 of 6702: 34.13906296627872% complete\n",
      "7.430617726051925% of data is None\n",
      "11:27:41\n",
      "2388 of 6702: 35.63115487914055% complete\n",
      "7.624589674723963% of data is None\n",
      "11:32:40\n",
      "2487 of 6702: 37.10832587287377% complete\n",
      "7.967770814682185% of data is None\n",
      "11:37:39\n",
      "2586 of 6702: 38.58549686660698% complete\n",
      "8.310951954640405% of data is None\n",
      "11:42:41\n",
      "2686 of 6702: 40.07758877946882% complete\n",
      "8.609370337212772% of data is None\n",
      "11:47:39\n",
      "2785 of 6702: 41.55475977320203% complete\n",
      "9.012235153685467% of data is None\n",
      "11:52:41\n",
      "2885 of 6702: 43.04685168606386% complete\n",
      "9.206207102357505% of data is None\n",
      "11:57:40\n",
      "2984 of 6702: 44.52402267979708% complete\n",
      "9.43002088928678% of data is None\n",
      "12:02:39\n",
      "3083 of 6702: 46.00119367353029% complete\n",
      "9.728439271859147% of data is None\n",
      "12:07:41\n",
      "3183 of 6702: 47.49328558639212% complete\n",
      "10.101462250074604% of data is None\n",
      "12:12:40\n",
      "3282 of 6702: 48.97045658012534% complete\n",
      "10.429722470904208% of data is None\n",
      "12:17:41\n",
      "3382 of 6702: 50.46254849298717% complete\n",
      "10.847508206505521% of data is None\n",
      "12:22:40\n",
      "3481 of 6702: 51.939719486720385% complete\n",
      "11.145926589077888% of data is None\n",
      "12:27:39\n",
      "3580 of 6702: 53.416890480453596% complete\n",
      "11.444344971650253% of data is None\n",
      "12:32:41\n",
      "3680 of 6702: 54.908982393315426% complete\n",
      "11.712921515965384% of data is None\n",
      "12:37:40\n",
      "3779 of 6702: 56.386153387048644% complete\n",
      "11.996418979409132% of data is None\n",
      "12:42:41\n",
      "3879 of 6702: 57.878245299910475% complete\n",
      "12.339600119367352% of data is None\n",
      "12:47:39\n",
      "3978 of 6702: 59.355416293643685% complete\n",
      "12.6230975828111% of data is None\n",
      "12:52:41\n",
      "4078 of 6702: 60.84750820650552% complete\n",
      "12.90659504625485% of data is None\n",
      "12:57:40\n",
      "4177 of 6702: 62.324679200238734% complete\n",
      "13.219934347955833% of data is None\n",
      "13:02:40\n",
      "4276 of 6702: 63.80185019397195% complete\n",
      "13.488510892270964% of data is None\n",
      "13:07:40\n",
      "4376 of 6702: 65.29394210683378% complete\n",
      "13.757087436586094% of data is None\n",
      "13:12:39\n",
      "4475 of 6702: 66.77111310056699% complete\n",
      "14.025663980901223% of data is None\n",
      "13:17:41\n",
      "4575 of 6702: 68.26320501342883% complete\n",
      "14.309161444344971% of data is None\n",
      "13:22:39\n",
      "4674 of 6702: 69.74037600716204% complete\n",
      "14.518054312145628% of data is None\n",
      "13:27:41\n",
      "4774 of 6702: 71.23246792002388% complete\n",
      "14.846314532975232% of data is None\n",
      "13:32:38\n",
      "4873 of 6702: 72.70963891375709% complete\n",
      "15.12981199641898% of data is None\n",
      "13:37:40\n",
      "4973 of 6702: 74.20173082661891% complete\n",
      "15.502834974634437% of data is None\n",
      "13:42:39\n",
      "5072 of 6702: 75.67890182035214% complete\n",
      "15.786332438078185% of data is None\n",
      "13:47:41\n",
      "5172 of 6702: 77.17099373321396% complete\n",
      "16.069829901521935% of data is None\n",
      "13:52:40\n",
      "5271 of 6702: 78.64816472694719% complete\n",
      "16.3682482840943% of data is None\n",
      "13:57:41\n",
      "5371 of 6702: 80.14025663980901% complete\n",
      "16.80095493882423% of data is None\n",
      "14:02:40\n",
      "5470 of 6702: 81.61742763354222% complete\n",
      "17.144136078782452% of data is None\n",
      "14:07:39\n",
      "5569 of 6702: 83.09459862727545% complete\n",
      "17.472396299612058% of data is None\n",
      "14:12:41\n",
      "5669 of 6702: 84.58669054013727% complete\n",
      "17.78573560131304% of data is None\n",
      "14:17:40\n",
      "5768 of 6702: 86.06386153387048% complete\n",
      "18.039391226499554% of data is None\n",
      "14:22:41\n",
      "5868 of 6702: 87.55595344673232% complete\n",
      "18.293046851686064% of data is None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RateLimiter caught an error, retrying (0/2 tries). Called with (*('france',), **{}).\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/garysimmons/opt/anaconda3/lib/python3.8/site-packages/urllib3/connection.py\", line 169, in _new_conn\n",
      "    conn = connection.create_connection(\n",
      "  File \"/Users/garysimmons/opt/anaconda3/lib/python3.8/site-packages/urllib3/util/connection.py\", line 96, in create_connection\n",
      "    raise err\n",
      "  File \"/Users/garysimmons/opt/anaconda3/lib/python3.8/site-packages/urllib3/util/connection.py\", line 86, in create_connection\n",
      "    sock.connect(sa)\n",
      "socket.timeout: timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/garysimmons/opt/anaconda3/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 699, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/Users/garysimmons/opt/anaconda3/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 382, in _make_request\n",
      "    self._validate_conn(conn)\n",
      "  File \"/Users/garysimmons/opt/anaconda3/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 1010, in _validate_conn\n",
      "    conn.connect()\n",
      "  File \"/Users/garysimmons/opt/anaconda3/lib/python3.8/site-packages/urllib3/connection.py\", line 353, in connect\n",
      "    conn = self._new_conn()\n",
      "  File \"/Users/garysimmons/opt/anaconda3/lib/python3.8/site-packages/urllib3/connection.py\", line 174, in _new_conn\n",
      "    raise ConnectTimeoutError(\n",
      "urllib3.exceptions.ConnectTimeoutError: (<urllib3.connection.HTTPSConnection object at 0x7fe323035040>, 'Connection to nominatim.openstreetmap.org timed out. (connect timeout=1)')\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/garysimmons/opt/anaconda3/lib/python3.8/site-packages/requests/adapters.py\", line 439, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/Users/garysimmons/opt/anaconda3/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 783, in urlopen\n",
      "    return self.urlopen(\n",
      "  File \"/Users/garysimmons/opt/anaconda3/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 783, in urlopen\n",
      "    return self.urlopen(\n",
      "  File \"/Users/garysimmons/opt/anaconda3/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 755, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/Users/garysimmons/opt/anaconda3/lib/python3.8/site-packages/urllib3/util/retry.py\", line 574, in increment\n",
      "    raise MaxRetryError(_pool, url, error or ResponseError(cause))\n",
      "urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=france&format=json&limit=1 (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x7fe323035040>, 'Connection to nominatim.openstreetmap.org timed out. (connect timeout=1)'))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/garysimmons/opt/anaconda3/lib/python3.8/site-packages/geopy/adapters.py\", line 448, in _request\n",
      "    resp = self.session.get(url, timeout=timeout, headers=headers)\n",
      "  File \"/Users/garysimmons/opt/anaconda3/lib/python3.8/site-packages/requests/sessions.py\", line 555, in get\n",
      "    return self.request('GET', url, **kwargs)\n",
      "  File \"/Users/garysimmons/opt/anaconda3/lib/python3.8/site-packages/requests/sessions.py\", line 542, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/Users/garysimmons/opt/anaconda3/lib/python3.8/site-packages/requests/sessions.py\", line 655, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/Users/garysimmons/opt/anaconda3/lib/python3.8/site-packages/requests/adapters.py\", line 504, in send\n",
      "    raise ConnectTimeout(e, request=request)\n",
      "requests.exceptions.ConnectTimeout: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=france&format=json&limit=1 (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x7fe323035040>, 'Connection to nominatim.openstreetmap.org timed out. (connect timeout=1)'))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/garysimmons/opt/anaconda3/lib/python3.8/site-packages/geopy/extra/rate_limiter.py\", line 136, in _retries_gen\n",
      "    yield i  # Run the function.\n",
      "  File \"/Users/garysimmons/opt/anaconda3/lib/python3.8/site-packages/geopy/extra/rate_limiter.py\", line 274, in __call__\n",
      "    res = self.func(*args, **kwargs)\n",
      "  File \"/Users/garysimmons/opt/anaconda3/lib/python3.8/site-packages/geopy/geocoders/nominatim.py\", line 297, in geocode\n",
      "    return self._call_geocoder(url, callback, timeout=timeout)\n",
      "  File \"/Users/garysimmons/opt/anaconda3/lib/python3.8/site-packages/geopy/geocoders/base.py\", line 368, in _call_geocoder\n",
      "    result = self.adapter.get_json(url, timeout=timeout, headers=req_headers)\n",
      "  File \"/Users/garysimmons/opt/anaconda3/lib/python3.8/site-packages/geopy/adapters.py\", line 438, in get_json\n",
      "    resp = self._request(url, timeout=timeout, headers=headers)\n",
      "  File \"/Users/garysimmons/opt/anaconda3/lib/python3.8/site-packages/geopy/adapters.py\", line 460, in _request\n",
      "    raise GeocoderUnavailable(message)\n",
      "geopy.exc.GeocoderUnavailable: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=france&format=json&limit=1 (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x7fe323035040>, 'Connection to nominatim.openstreetmap.org timed out. (connect timeout=1)'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14:27:41\n",
      "5965 of 6702: 89.0032826022083% complete\n",
      "18.516860638615338% of data is None\n",
      "14:32:40\n",
      "6064 of 6702: 90.48045359594151% complete\n",
      "18.830199940316323% of data is None\n",
      "14:37:39\n",
      "6163 of 6702: 91.95762458967472% complete\n",
      "19.173381080274545% of data is None\n",
      "14:42:40\n",
      "6263 of 6702: 93.44971650253656% complete\n",
      "19.531483139361384% of data is None\n",
      "14:47:39\n",
      "6362 of 6702: 94.92688749626977% complete\n",
      "19.859743360190986% of data is None\n",
      "14:52:41\n",
      "6462 of 6702: 96.41897940913161% complete\n",
      "20.21784541927783% of data is None\n",
      "14:57:40\n",
      "6561 of 6702: 97.89615040286482% complete\n",
      "20.516263801850194% of data is None\n",
      "15:02:39\n",
      "6660 of 6702: 99.37332139659803% complete\n",
      "20.99373321396598% of data is None\n"
     ]
    }
   ],
   "source": [
    "if ((\"partnerDistance\" not in datingTrainWithoutDummies.columns) or \n",
    "    (\"partnerDistance\" not in datingTrainWithDummies.columns)):\n",
    "    datingTrainWithoutDummies = util.returnDFWithpartnerDistance(datingTrainWithoutDummies,\"train\",True)\n",
    "    datingTrainWithDummies[\"partnerDistance\"] = datingTrainWithoutDummies[\"partnerDistance\"]\n",
    "    datingTrainWithDummies.to_csv('../data/datingTrainWithDummies.csv',index=False)\n",
    "    datingTrainWithoutDummies.to_csv('../data/datingTrainWithoutDummies.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d629b9d5-3238-4fe4-bdc7-421fb93ea28d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Fix ambiguous scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ede98e0-c807-43b3-976b-4728aece576b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-7-80fedd74ddb2>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-7-80fedd74ddb2>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    halfwayChangeColumnsFromWithDummies = [str(col) if ((\"1_s\" in str(col)) | (\"3_s\" in str(col))) for col in datingTrainWithDummies]\u001b[0m\n\u001b[0m                                                                                                   ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "halfwayChangeColumnsFromWithDummies = [str(col) if ((\"1_s\" in str(col)) | (\"3_s\" in str(col))) for col in datingTrainWithDummies]\n",
    "halfwayChangeColumnsFromWithoutDummies = [str(col) if ((\"1_s\" in str(col)) | (\"3_s\" in str(col))) for col in datingTrainWithoutDummies]\n",
    "\n",
    "if(len(halfwayChangeColumnsFromWithDummies) + len(halfwayChangeColumnsFromWithoutDummies) > 0):\n",
    "    for question in pointDistributionList:\n",
    "        questionCols = [str(col) if (question in datingTrainWithDummies)]\n",
    "        datingTrainWithDummies[f'{question}_sum'] = datingTrainWithDummies[questionCols].sum(axis = 1)\n",
    "        datingTrainWithoutDummies[f'{question}_sum'] = datingTrainWithoutDummies[questionCols].sum(axis = 1)\n",
    "        for questionCol in questionCols:\n",
    "            datingTrainWithDummies[str(questionCol)] = datingTrainWithDummies[str(questionCol)] * 100 / datingTrainWithDummies[f'{question}_sum']\n",
    "            datingTrainWithoutDummies[str(questionCol)] = datingTrainWithoutDummies[str(questionCol)] * 100 / datingTrainWithoutDummies[f'{question}_sum']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4444c2d-2bae-4e16-848d-5035c7700c62",
   "metadata": {},
   "source": [
    "### Replace Nans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a1fe4d-f74a-4a20-a5e5-9924a44d97bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "911fcbe2-48f5-470d-8dbf-d59feb48cec9",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fccf544a-51dc-4d1d-9619-654cc93ac168",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5508ffa-dea4-49d3-8d1c-333f80a4f625",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b973841e-f4c8-465c-b56a-8d23896d59dc",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "767c1e00-aac9-487b-92b6-b0766b1ab8b9",
   "metadata": {},
   "source": [
    "## Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e0d71d-dbd6-4075-8f9e-fc57118d0ee4",
   "metadata": {},
   "source": [
    "# Individual Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e41fa1-50ce-4fd6-85b3-c9ec47b37a53",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe7aec2-8e5e-4b55-8feb-c22af75e031d",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f77cabc1-2855-4ac3-987f-61546d0b7da8",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2830fb95-9857-4d16-b538-62c025b07b47",
   "metadata": {},
   "source": [
    "## Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87fa7875-d2a8-4e24-aa49-25d005b1e8a5",
   "metadata": {},
   "source": [
    "# Ensemble Testing"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
