{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "283e38b5-dbdb-48a3-901b-2d4c6fe803f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from os.path import exists\n",
    "from os import remove\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.model_selection as ms\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import metrics\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, \"../util/\")\n",
    "import util as util"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f53352-c019-4b18-ad90-c9ec7e010d29",
   "metadata": {},
   "source": [
    "# Adding dummies and train-test-split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f609dd8-54ac-4fdf-929d-1c6870d95fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "maleTrainWithDummiesExists = exists('../data/male/maleTrainWithDummies.csv')\n",
    "maleTestWithDummiesExists = exists('../data/male/maleTestWithDummies.csv')\n",
    "maleTrainWithoutDummiesExists = exists('../data/male/maleTrainWithoutDummies.csv')\n",
    "maleTestWithoutDummiesExists = exists('../data/male/maleTestWithoutDummies.csv')\n",
    "maleFullWithDummiesExists = exists('../data/male/maleFullWithDummies.csv')\n",
    "maleFullWithoutDummiesExists = exists('../data/male/maleFullWithoutDummies.csv')\n",
    "\n",
    "femaleTrainWithDummiesExists = exists('../data/female/femaleTrainWithDummies.csv')\n",
    "femaleTestWithDummiesExists = exists('../data/female/femaleTestWithDummies.csv')\n",
    "femaleTrainWithoutDummiesExists = exists('../data/female/femaleTrainWithoutDummies.csv')\n",
    "femaleTestWithoutDummiesExists = exists('../data/female/femaleTestWithoutDummies.csv')\n",
    "femaleFullWithDummiesExists = exists('../data/female/femaleFullWithDummies.csv')\n",
    "femaleFullWithoutDummiesExists = exists('../data/female/femaleFullWithoutDummies.csv')\n",
    "\n",
    "relatedDummiesDictionaryExists = exists('../data/relatedDummiesDictionary.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6bdd5e57-935f-47f6-baa4-506a1ec62765",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/columnDataDictionary.json') as d:\n",
    "    columnDataDictionary = json.load(d)\n",
    "columnList = columnDataDictionary['columnList']\n",
    "nonBinaryCategoricalList = columnDataDictionary['nonBinaryCategoricalList']\n",
    "stringToFloatList = columnDataDictionary['stringToFloatList']\n",
    "pointDistributionList = columnDataDictionary['pointDistributionList']\n",
    "partnerList = columnDataDictionary['partnerList']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c38d144-9101-4d6a-802b-192a9d08ac73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/garysimmons/opt/anaconda3/bin/jupyter-nbconvert\", line 11, in <module>\n",
      "    sys.exit(main())\n",
      "  File \"/Users/garysimmons/opt/anaconda3/lib/python3.8/site-packages/jupyter_core/application.py\", line 254, in launch_instance\n",
      "    return super(JupyterApp, cls).launch_instance(argv=argv, **kwargs)\n",
      "  File \"/Users/garysimmons/opt/anaconda3/lib/python3.8/site-packages/traitlets/config/application.py\", line 845, in launch_instance\n",
      "    app.start()\n",
      "  File \"/Users/garysimmons/opt/anaconda3/lib/python3.8/site-packages/nbconvert/nbconvertapp.py\", line 350, in start\n",
      "    self.convert_notebooks()\n",
      "  File \"/Users/garysimmons/opt/anaconda3/lib/python3.8/site-packages/nbconvert/nbconvertapp.py\", line 512, in convert_notebooks\n",
      "    raise ValueError(\n",
      "ValueError: Please specify an output format with '--to <format>'.\n",
      "The following formats are available: ['asciidoc', 'custom', 'html', 'latex', 'markdown', 'notebook', 'pdf', 'python', 'rst', 'script', 'slides', 'webpdf']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-1c0e99690bf4>:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  blindDateData[col] = blindDateData[col].apply(str)\n",
      "<ipython-input-4-1c0e99690bf4>:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  blindDateData[col]=blindDateData[col].fillna('nan')\n",
      "<ipython-input-4-1c0e99690bf4>:74: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  maleTrainWithDummies['dec_o'] = femaleChoiceTrain\n",
      "<ipython-input-4-1c0e99690bf4>:75: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  maleTestWithDummies['dec_o'] = femaleChoiceTest\n",
      "<ipython-input-4-1c0e99690bf4>:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  femaleTrainWithDummies['dec_o'] = maleChoiceTrain\n",
      "<ipython-input-4-1c0e99690bf4>:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  femaleTestWithDummies['dec_o'] = maleChoiceTest\n"
     ]
    }
   ],
   "source": [
    "if (maleTrainWithDummiesExists and maleTestWithDummiesExists and maleFullWithDummiesExists and\n",
    "    maleTrainWithoutDummiesExists and maleTestWithoutDummiesExists and maleFullWithoutDummiesExists and\n",
    "    femaleTrainWithDummiesExists and femaleTestWithDummiesExists and femaleFullWithDummiesExists and\n",
    "    femaleTrainWithoutDummiesExists and femaleTestWithoutDummiesExists and femaleFullWithoutDummiesExists and\n",
    "    relatedDummiesDictionaryExists):\n",
    "    maleTrainWithDummies = pd.read_csv('../data/male/maleTrainWithDummies.csv')\n",
    "    maleTestWithDummies = pd.read_csv('../data/male/maleTestWithDummies.csv')\n",
    "    maleTrainWithoutDummies = pd.read_csv('../data/male/maleTrainWithoutDummies.csv')\n",
    "    maleTestWithoutDummies = pd.read_csv('../data/male/maleTestWithoutDummies.csv')\n",
    "    maleFullWithDummies = pd.read_csv('../data/male/maleFullWithDummies.csv')\n",
    "    maleFullWithoutDummies = pd.read_csv('../data/male/maleFullWithoutDummies.csv')\n",
    "    \n",
    "    femaleTrainWithDummies = pd.read_csv('../data/female/femaleTrainWithDummies.csv')\n",
    "    femaleTestWithDummies = pd.read_csv('../data/female/femaleTestWithDummies.csv')\n",
    "    femaleTrainWithoutDummies = pd.read_csv('../data/female/femaleTrainWithoutDummies.csv')\n",
    "    femaleTestWithoutDummies = pd.read_csv('../data/female/femaleTestWithoutDummies.csv')\n",
    "    femaleFullWithDummies = pd.read_csv('../data/female/femaleFullWithDummies.csv')\n",
    "    femaleFullWithoutDummies = pd.read_csv('../data/female/femaleFullWithoutDummies.csv')\n",
    "    \n",
    "    with open('../data/relatedDummiesDictionary.json') as d:\n",
    "        relatedDummiesDictionary = json.load(d)\n",
    "    for df in [maleTrainWithDummies,maleTestWithDummies,maleFullWithDummies,maleTrainWithoutDummies,maleTestWithoutDummies,maleFullWithoutDummies,\n",
    "               femaleTrainWithDummies,femaleTestWithDummies,femaleFullWithDummies,femaleTrainWithoutDummies,femaleTestWithoutDummies,femaleFullWithoutDummies]:\n",
    "        for col in nonBinaryCategoricalList:\n",
    "            df[col] = df[col].apply(str)\n",
    "else:\n",
    "    !rm -r ../data/male\n",
    "    !mkdir ../data/male\n",
    "    !rm -r ../data/female\n",
    "    !mkdir ../data/female\n",
    "    \n",
    "    !jupyter nbconvert --execute eda.ipynb\n",
    "    \n",
    "    datingData = pd.read_csv('../data/encoded-SpeedDatingData.csv')\n",
    "    blindDateData = datingData[columnList]\n",
    "    for col in nonBinaryCategoricalList:\n",
    "        blindDateData[col] = blindDateData[col].apply(str)\n",
    "        \n",
    "    blindDateCategoricalData = blindDateData.select_dtypes(include=['O'])\n",
    "    for col in blindDateCategoricalData.columns:\n",
    "        blindDateData[col]=blindDateData[col].fillna('nan')\n",
    "    relatedDummiesDictionary = {}\n",
    "    for col in blindDateCategoricalData.columns:\n",
    "        dummyData = pd.get_dummies(blindDateData[col],prefix=col,drop_first=True)\n",
    "        for dummyCol in dummyData.columns:\n",
    "            relatedDummiesDictionary[str(dummyCol)] = list(dummyData.columns)\n",
    "            if col in partnerList:\n",
    "                partnerList.append(str(dummyCol))\n",
    "        blindDateData = pd.concat([blindDateData,dummyData],axis=1)\n",
    "    with open('../data/relatedDummiesDictionary.json', 'w') as fp:\n",
    "        json.dump(relatedDummiesDictionary, fp)\n",
    "        \n",
    "    partnerList = list(set(partnerList))\n",
    "    columnDataDictionary = {\"columnList\": columnList,\n",
    "                        \"nonBinaryCategoricalList\": nonBinaryCategoricalList,\n",
    "                        \"stringToFloatList\": stringToFloatList,\n",
    "                        \"pointDistributionList\": pointDistributionList,\n",
    "                        \"partnerList\": partnerList}\n",
    "\n",
    "    with open('../data/columnDataDictionary.json', 'w') as fp:\n",
    "            json.dump(columnDataDictionary, fp)\n",
    "    \n",
    "    maleFullWithDummies = blindDateData[blindDateData['gender'] == 1]\n",
    "    femaleFullWithDummies = blindDateData[blindDateData['gender'] == 0]\n",
    "    \n",
    "    femaleChoice = maleFullWithDummies['dec_o']\n",
    "    XMale = maleFullWithDummies.drop(['dec_o'], axis=1)\n",
    "    maleChoice = femaleFullWithDummies['dec_o']\n",
    "    XFemale = femaleFullWithDummies.drop(['dec_o'], axis=1)\n",
    "    \n",
    "    maleTrainWithDummies, maleTestWithDummies, femaleChoiceTrain, femaleChoiceTest = train_test_split(XMale, femaleChoice, test_size=0.2)\n",
    "    femaleTrainWithDummies, femaleTestWithDummies, maleChoiceTrain, maleChoiceTest = train_test_split(XFemale, maleChoice, test_size=0.2)\n",
    "    \n",
    "    maleTrainWithDummies['dec_o'] = femaleChoiceTrain\n",
    "    maleTestWithDummies['dec_o'] = femaleChoiceTest\n",
    "    femaleTrainWithDummies['dec_o'] = maleChoiceTrain\n",
    "    femaleTestWithDummies['dec_o'] = maleChoiceTest\n",
    "    \n",
    "    maleTrainWithDummies.to_csv('../data/male/maleTrainWithDummies.csv',index=False)\n",
    "    maleTestWithDummies.to_csv('../data/male/maleTestWithDummies.csv',index=False)\n",
    "    maleFullWithDummies.to_csv('../data/male/maleFullWithDummies.csv',index=False)\n",
    "    \n",
    "    femaleTrainWithDummies.to_csv('../data/female/femaleTrainWithDummies.csv',index=False)\n",
    "    femaleTestWithDummies.to_csv('../data/female/femaleTestWithDummies.csv',index=False)\n",
    "    femaleFullWithDummies.to_csv('../data/female/femaleFullWithDummies.csv',index=False)\n",
    "    \n",
    "    dummyColumns = list(relatedDummiesDictionary.keys())\n",
    "    maleTrainWithoutDummies = maleTrainWithDummies.drop(dummyColumns, axis=1)\n",
    "    maleTestWithoutDummies = maleTestWithDummies.drop(dummyColumns, axis=1)\n",
    "    maleFullWithoutDummies = maleFullWithDummies.drop(dummyColumns, axis=1)\n",
    "    femaleTrainWithoutDummies = femaleTrainWithDummies.drop(dummyColumns, axis=1)\n",
    "    femaleTestWithoutDummies = femaleTestWithDummies.drop(dummyColumns, axis=1)\n",
    "    femaleFullWithoutDummies = femaleFullWithDummies.drop(dummyColumns, axis=1)\n",
    "    \n",
    "    maleTrainWithoutDummies.to_csv('../data/male/maleTrainWithoutDummies.csv',index=False)\n",
    "    maleTestWithoutDummies.to_csv('../data/male/maleTestWithoutDummies.csv',index=False)\n",
    "    maleFullWithoutDummies.to_csv('../data/male/maleFullWithoutDummies.csv',index=False)\n",
    "    femaleTrainWithoutDummies.to_csv('../data/female/femaleTrainWithoutDummies.csv',index=False)\n",
    "    femaleTestWithoutDummies.to_csv('../data/female/femaleTestWithoutDummies.csv',index=False)\n",
    "    femaleFullWithoutDummies.to_csv('../data/female/femaleFullWithoutDummies.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c695ed-1396-49fb-ae29-736e77d59d69",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31bd5935-9cb3-4118-97ab-8d99239810d5",
   "metadata": {},
   "source": [
    "### Female"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ebd90ed-cccb-437b-a07e-1b153772db7c",
   "metadata": {},
   "source": [
    "#### Join partner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3addb68-04fb-4afe-a7c8-dbd8d6825eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "femaleTrainWithDummies = util.joinToPartner(femaleTrainWithDummies,maleFullWithDummies)\n",
    "femaleTrainWithoutDummies = util.joinToPartner(femaleTrainWithoutDummies,maleFullWithoutDummies)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de70f81-b475-42fe-9dc7-8c107f2d28f8",
   "metadata": {},
   "source": [
    "#### Get distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4da6bb-d52b-4a7f-8ece-fe8de5dcea23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2f41cb9f-95a8-4514-b963-a6053eeb96aa",
   "metadata": {},
   "source": [
    "#### Fix ambiguous scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e301ac-924d-41fe-8476-4690c13693f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d4444c2d-2bae-4e16-848d-5035c7700c62",
   "metadata": {},
   "source": [
    "#### Replace Nans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a1fe4d-f74a-4a20-a5e5-9924a44d97bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1b0b101a-e013-4017-9e2e-21b5a61dd9cf",
   "metadata": {},
   "source": [
    "### Male"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2402e73d-e3cc-4f9b-ba72-c5e684c1a63d",
   "metadata": {},
   "source": [
    "#### Join partner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c966319a-34dc-4631-bfab-79418f10c201",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6c04c0ef-fe68-4917-9795-59e4fe87385e",
   "metadata": {},
   "source": [
    "#### Get distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75e668a-850b-44df-803d-ef08c678ffd0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3cb3b13e-5091-4ab8-8a45-738477360af1",
   "metadata": {},
   "source": [
    "#### Fix ambiguous scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e0d94f4-336c-499e-b87d-99b1276fd6a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0bcd3c76-b57d-4377-95f0-2707ff4e8cbb",
   "metadata": {},
   "source": [
    "#### Replace Nans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94cb57ff-934b-4f8e-951d-a0f8674c9281",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "911fcbe2-48f5-470d-8dbf-d59feb48cec9",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fccf544a-51dc-4d1d-9619-654cc93ac168",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5508ffa-dea4-49d3-8d1c-333f80a4f625",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b973841e-f4c8-465c-b56a-8d23896d59dc",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "767c1e00-aac9-487b-92b6-b0766b1ab8b9",
   "metadata": {},
   "source": [
    "## Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e0d71d-dbd6-4075-8f9e-fc57118d0ee4",
   "metadata": {},
   "source": [
    "# Individual Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e41fa1-50ce-4fd6-85b3-c9ec47b37a53",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe7aec2-8e5e-4b55-8feb-c22af75e031d",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f77cabc1-2855-4ac3-987f-61546d0b7da8",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2830fb95-9857-4d16-b538-62c025b07b47",
   "metadata": {},
   "source": [
    "## Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87fa7875-d2a8-4e24-aa49-25d005b1e8a5",
   "metadata": {},
   "source": [
    "# Ensemble Testing"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
