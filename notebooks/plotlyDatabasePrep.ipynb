{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4a61d0-01e5-4cfb-b0b7-d6af105e1b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from os.path import exists\n",
    "from os import remove\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.model_selection as ms\n",
    "import sklearn.metrics as sm\n",
    "from sklearn.model_selection import cross_validate\n",
    "import sklearn.linear_model as lm\n",
    "from sklearn.neighbors import KNeighborsClassifier as knn\n",
    "from sklearn.ensemble import GradientBoostingClassifier as grad\n",
    "from sklearn.ensemble import RandomForestClassifier as rf\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn import metrics\n",
    "import scipy.stats as stats\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import requests\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, \"../src/\")\n",
    "import util as util\n",
    "\n",
    "%autosave 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0caf4af0-74cf-46e3-a6b1-1224abc9bf81",
   "metadata": {},
   "source": [
    "# Grab datingFull.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc416b1-d4d3-470e-a588-5b2ea27708d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/processedData/columnDataDictionary.json') as d:\n",
    "    columnDataDictionary = json.load(d)\n",
    "if exists('../data/plotlyDashData/datingFull.csv'):\n",
    "    datingFull = pd.read_csv('../data/plotlyDashData/datingFull.csv')\n",
    "else:\n",
    "    datingFull = pd.read_csv('../data/processedData/datingFull.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05000317-abc5-4f37-b05e-0be2d2bc07c7",
   "metadata": {},
   "source": [
    "# Stringify specified columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9bbc77a-8b4c-4764-a3ee-dee3514f94ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "datingFull = util.stringifyCategoricalColumns(datingFull)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc1c4665-505c-4aab-9e4e-11dca09bbfa4",
   "metadata": {},
   "source": [
    "# Ensure datingFull has locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b73009-0260-4a03-a932-3c87df922d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if(\"lats\" not in datingFull.columns or \"lons\" not in datingFull.columns):\n",
    "    datingFull = util.getLocations(datingFull,True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ba4ece-62e9-4736-9dad-e9696e6b54eb",
   "metadata": {},
   "source": [
    "# Join to partner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e5f2ec0-a8f4-444c-8606-90376d414eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "if (\"iid\" in datingFull.columns) or (\"pid\" in datingFull.columns):\n",
    "    partner = datingFull.copy()\n",
    "    datingFull = util.joinToPartner(datingFull,partner).drop([\"iid\",\"pid\",\"iid_o\",\"pid_o\"],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f82752d-730a-4800-8ebc-392d969d89ee",
   "metadata": {},
   "source": [
    "# Fix Ambiguous Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea8f5bc-54aa-4886-9b4f-e0b1089c1f82",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "halfwayChangeColumns = [str(col) for col in datingFull.columns if ((\"1_s\" in str(col)) | (\"3_s\" in str(col)))]\n",
    "\n",
    "if(len(halfwayChangeColumns) > 0):\n",
    "    datingFull = util.fixAmbiguousScores(datingFull)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "068f8fda-0c05-44b1-97e5-d6681bd6af25",
   "metadata": {},
   "source": [
    "# Replace Nans and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab5de1a-57c6-4b97-b4a2-39c0e14d108a",
   "metadata": {},
   "outputs": [],
   "source": [
    "datingFullNumerical = datingFull.select_dtypes(include=['uint8','int64','float64']).drop(\"match\",axis=1)\n",
    "datingFullNumerical = util.replaceNansWithTrainingDataValues(datingFullNumerical)\n",
    "for col in datingFullNumerical.columns:\n",
    "    datingFull[col] = datingFullNumerical[col]\n",
    "datingFull.to_csv('../data/plotlyDashData/datingFull.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b3eb1f-4192-4c16-a1c1-728390951c86",
   "metadata": {},
   "source": [
    "# Prepare profile database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1bde98c-981f-4995-ba52-2c3865d66491",
   "metadata": {},
   "outputs": [],
   "source": [
    "nameDictionary = dict()\n",
    "uniqueNames = []\n",
    "if exists('../data/nameDictionary.json'):\n",
    "    with open('../data/nameDictionary.json') as d:\n",
    "        nameDictionary = json.load(d)\n",
    "        uniqueNames = nameDictionary[\"uniqueNames\"]\n",
    "\n",
    "if exists('../data/plotlyDashData/profileData.csv'):\n",
    "    profileData = pd.read_csv('../data/plotlyDashData/profileData.csv')\n",
    "    profileData = util.stringifyCategoricalColumns(profileData)\n",
    "            \n",
    "else:\n",
    "    preprofileData = pd.read_csv('../data/encoded-SpeedDatingData-WithLocations.csv')\n",
    "    profileList = [\"iid\",\"gender\",\"age\",\"race\",\"field_cd\",\"order\",\"round\",\"undergra\",\"mn_sat\",\"tuition\",\"imprace\",\"imprelig\",\"from\",\"zipcode\",\"income\",\n",
    "                   \"goal\",\"date\",\"go_out\",\"career_c\",\"sports\",\"tvsports\",\"career\",\n",
    "                  \"exercise\",\"dining\",\"museums\",\"art\",\"hiking\",\"gaming\",\"clubbing\",\"reading\",\"tv\",\"theater\",\"movies\",\"concerts\",\"music\",\"shopping\",\"yoga\",\n",
    "                  \"exphappy\",\"expnum\",\"attr1_1\",\"sinc1_1\",\"intel1_1\",\"fun1_1\",\"shar1_1\",\"attr4_1\",\"sinc4_1\",\"intel4_1\",\"fun4_1\",\"shar4_1\",\n",
    "                  \"attr2_1\",\"sinc2_1\",\"intel2_1\",\"fun2_1\",\"shar2_1\",\"attr3_1\",\"sinc3_1\",\"intel3_1\",\"fun3_1\",\"attr5_1\",\"sinc5_1\",\"intel5_1\",\n",
    "                  \"fun5_1\",\"match_es\",\"attr1_s\",\"sinc1_s\",\"intel1_s\",\"fun1_s\",\"shar1_s\",\"attr3_s\",\"sinc3_s\",\"intel3_s\",\"fun3_s\",\"lats\",\"lons\"]\n",
    "    \n",
    "    preprofileData = preprofileData[profileList]\n",
    "    \n",
    "    preprofileData = util.switchNumbersAndCategoriesFromRawData(preprofileData)\n",
    "\n",
    "    #fix ambiguous scores\n",
    "    halfwayChangeColumns = [str(col) for col in preprofileData.columns if ((\"1_s\" in str(col)) | (\"3_s\" in str(col)))]\n",
    "\n",
    "    if(len(halfwayChangeColumns) > 0):\n",
    "        oldOrders = preprofileData[\"order\"]\n",
    "        preprofileData = util.fixAmbiguousScores(preprofileData)\n",
    "        util.halfwayQuestionSanityTest(preprofileData,\" post-fixAmbiguousScores and pre-saving\")\n",
    "        preprofileData[\"order\"] = oldOrders\n",
    "    \n",
    "    #nanReplacement\n",
    "    preprofileData = util.replaceNansWithTrainingDataValues(preprofileData)\n",
    "    \n",
    "    #Create profile and database\n",
    "    uniqueIIDs = list(set(preprofileData[\"iid\"]))\n",
    "    firstIID = str(uniqueIIDs[0])\n",
    "    for iid in uniqueIIDs:\n",
    "        name = \"\"\n",
    "        personid = str(iid)\n",
    "        \n",
    "        person = preprofileData.loc[preprofileData[\"iid\"]==iid]\n",
    "        person = person.loc[person[\"order\"]==person[\"order\"].max()]\n",
    "        person = person.iloc[[0]]\n",
    "        \n",
    "        if type(person) != pd.DataFrame:\n",
    "            print(type(person))\n",
    "            breakMeImNotADF\n",
    "        if person.shape[1] == 1:\n",
    "            breakMeImAColumn\n",
    "        \n",
    "        if personid not in nameDictionary.keys():\n",
    "            api_url = \"https://api.namefake.com/\"\n",
    "            if person[\"gender\"].any() == 0:\n",
    "                api_url += \"female\"\n",
    "            else:\n",
    "                api_url += \"male\"\n",
    "\n",
    "            name = requests.get(api_url).json()[\"name\"]\n",
    "            if name in uniqueNames:\n",
    "                while name in uniqueNames:\n",
    "                    name = requests.get(api_url).json()[\"name\"]\n",
    "            \n",
    "            uniqueNames.append(name)\n",
    "            nameDictionary[personid] = name\n",
    "        else:\n",
    "            name = nameDictionary[str(iid)]\n",
    "        \n",
    "        nameDictionary[\"uniqueNames\"] = uniqueNames\n",
    "        with open('../data/nameDictionary.json', 'w') as fp:\n",
    "            json.dump(nameDictionary, fp)\n",
    "        \n",
    "        person[\"name\"] = name\n",
    "        if personid == firstIID:\n",
    "            profileData = person\n",
    "        else:\n",
    "            profileData = pd.concat([profileData,person])\n",
    "        \n",
    "    profileData.drop(\"order\",axis=1).to_csv('../data/plotlyDashData/profileData.csv',index=False)\n",
    "    \n",
    "if exists('../data/plotlyDashData/partnerProfileWithDummies.csv'):\n",
    "    partnerProfileWithDummies = pd.read_csv('../data/plotlyDashData/partnerProfileWithDummies.csv')\n",
    "    partnerProfileWithDummies = util.stringifyCategoricalColumns(partnerProfileWithDummies)\n",
    "else:                   \n",
    "    partnerProfileWithDummies = util.addDummies(profileData.copy())\n",
    "    partnerProfileWithDummies[\"race_5.0\"] = 0 #no native americans, thus excluded from original dummification method\n",
    "    partnerProfileWithDummies = util.replaceNansWithTrainingDataValues(partnerProfileWithDummies)            \n",
    "    partnerProfileWithDummies.to_csv('../data/plotlyDashData/partnerProfileWithDummies.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b9a7f20-b969-4ee9-a1d1-7eb8db26595a",
   "metadata": {},
   "source": [
    "# Missing column analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e51cda-6120-43ee-8b11-75815bea8950",
   "metadata": {},
   "outputs": [],
   "source": [
    "colList = list(partnerProfileWithDummies.columns)\n",
    "for col in colList:\n",
    "    if col in columnDataDictionary[\"nonBinaryCategoricalList\"]:\n",
    "        partnerProfileWithDummies[col] = partnerProfileWithDummies[col].apply(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6c0e2e-a3d2-439a-bc23-00758cda2463",
   "metadata": {},
   "outputs": [],
   "source": [
    "columnsCollected = [str(col) for col in partnerProfileWithDummies.columns] + [str(col)+\"_o\" for col in partnerProfileWithDummies.columns]\n",
    "missingColumns = []\n",
    "unneccesaryColumns = [\"samerace\",\"match\"]\n",
    "necessaryColumns = pd.read_csv('../data/plotlyDashData/datingTrain.csv').drop(unneccesaryColumns,axis=1).columns\n",
    "for necCol in necessaryColumns:\n",
    "    if necCol not in columnsCollected:\n",
    "        missingColumns.append(necCol)\n",
    "\n",
    "print(\"from profile data\")\n",
    "for col in datingFull.columns:\n",
    "    if col in missingColumns and \"_o\" not in col:\n",
    "        print(col)\n",
    "\n",
    "print(\"\\nfrom partner data\")\n",
    "for col in datingFull.columns:\n",
    "    if col in missingColumns and \"_o\" in col:\n",
    "        print(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f2ece5e-756c-4539-bf06-8e95b6d07581",
   "metadata": {},
   "source": [
    "# Create Description Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21eae6e-c91d-4daa-bd04-3b11fb5c214b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if exists(\"../data/plotlyDashData/descriptionDictionary.json\") == False:\n",
    "    descriptionDictionary = dict()\n",
    "    if exists(\"../data/descriptionDictionary.json\"):\n",
    "        with open(\"../data/descriptionDictionary.json\") as d:\n",
    "            descriptionDictionary = json.load(d)\n",
    "    \n",
    "    fullColumns = list(datingFull.columns)\n",
    "    profileColumns = list(profileData.columns)\n",
    "    columnsNeedingDescriptions = fullColumns + profileColumns\n",
    "    for col in columnsNeedingDescriptions:\n",
    "        strcol = str(col)\n",
    "        if strcol not in descriptionDictionary.keys():\n",
    "            print(s)\n",
    "            desc = input()\n",
    "            descriptionDictionary[strcol] = desc\n",
    "\n",
    "    with open(\"../data/plotlyDashData/descriptionDictionary.json\",\"w\") as fp:\n",
    "        json.dump(descriptionDictionary,fp)\n",
    "    with open(\"../data/descriptionDictionary.json\",\"w\") as fp:\n",
    "        json.dump(descriptionDictionary,fp)\n",
    "\n",
    "with open(\"../data/plotlyDashData/descriptionDictionary.json\") as d:\n",
    "    descriptionDictionary = json.load(d)\n",
    "    \n",
    "for k in descriptionDictionary.keys():\n",
    "    print(f\"{k}: {descriptionDictionary[k]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
